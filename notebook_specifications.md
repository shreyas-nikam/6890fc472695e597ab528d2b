
# Jupyter Notebook Specification: Model Development for PD Models

## 1. Notebook Overview

**Learning Goals:**

*   Understand the concepts of Through-the-Cycle (TTC) and Point-in-Time (PIT) Probability of Default (PD) models.
*   Learn to derive TTC PDs from historical data, including cycle adjustments and handling low-default portfolios.
*   Implement PIT PD models incorporating macroeconomic factors.
*   Generate multi-year PD term structures.
*   Create reproducible artefacts for model validation and further development.

**Expected Outcomes:**

*   A Jupyter Notebook that computes TTC PDs, builds a PIT PD model, and generates PD term structures.
*   A set of cleaned data and trained models saved as reusable artefacts.
*   Visualizations to demonstrate model behavior and validity.

## 2. Mathematical and Theoretical Foundations

### 2.1 Through-the-Cycle (TTC) PD

The TTC PD represents the long-run average default rate for a given rating grade, averaged over a complete economic cycle. This metric aims to smooth out short-term fluctuations and provide a stable, long-term view of credit risk.

*   **Definition:** The TTC PD is calculated as the average of observed default rates for a rating grade over a sufficiently long historical period that covers at least one full economic cycle.
    $$TTC\_PD_{grade} = \frac{1}{n} \sum_{t=1}^{n} DefaultRate_{grade, t}$$
    where $n$ is the number of periods in the historical data.

*   **Real-World Applications:** TTC PDs are used in regulatory capital calculations (e.g., Basel II/III), stress testing, and long-term credit risk management.

*   **Cycle Adjustment:** If the historical data does not fully capture an economic cycle, adjustments are needed to account for stressed periods. This can involve adding an uplift to the PD based on expert judgment or historical loss data from crisis periods.

### 2.2 Point-in-Time (PIT) PD

The PIT PD reflects the current default risk of an obligor, incorporating both its rating grade and prevailing macroeconomic conditions.

*   **Definition:** The PIT PD is a function of the rating grade and a set of macroeconomic variables. Several modeling approaches can be used, including logistic regression, survival models, and single-factor Vasicek models.

* **Multivariate Logistic Regression**

    The probability of default can be modeled using a multivariate logistic regression. The model can be represented as:
    $$P(Default = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 * RatingGrade + \beta_2 * MacroVar_1 + \beta_3 * MacroVar_2 + ...)}}$$
    Where:
    - $P(Default = 1)$ is the probability of default.
    - $\beta_0$ is the intercept.
    - $\beta_1, \beta_2, \beta_3 ...$ are the coefficients for the respective variables (RatingGrade, MacroVar_1, MacroVar_2, ...).

* **Single-Factor Vasicek Model**
The Vasicek model is a commonly used model for credit risk. In this case, for stress testing and scenario analysis,
$$PD_{PIT} = N\left( \frac{N^{-1}(PD_{TTC}) + \sqrt{\rho} Z}{\sqrt{1-\rho}} \right)$$
Where:
- $PD_{PIT}$ is the Point-in-Time probability of default.
- $PD_{TTC}$ is the Through-the-Cycle probability of default.
- $N(\cdot)$ is the cumulative standard normal distribution function.
- $N^{-1}(\cdot)$ is the inverse cumulative standard normal distribution function.
- $\rho$ is the asset correlation.
- $Z$ is a systemic factor (driven by macro conditions)

*   **Real-World Applications:** PIT PDs are used for pricing credit products, provisioning, and active portfolio management.

### 2.3 Pluto-&-Tasche/Bayesian Techniques for Low-Default Grades

When dealing with low-default portfolios or rating grades with few defaults, specialized estimation techniques are required to derive statistically sound PD estimates. Pluto-&-Tasche and Bayesian methods are common approaches.

*   **Pluto-&-Tasche:** This method estimates the probability of default using a binomial model and adjusts for the uncertainty in the observed default rate.

*   **Bayesian Estimation:** Bayesian methods incorporate prior beliefs about the PD and update them with observed data to obtain a posterior distribution of the PD. This approach can provide more stable and reliable estimates when data is scarce.

### 2.4 PD Term Structure

The PD term structure represents the probability of default over multiple time horizons. It is used for long-term credit risk assessment and valuation.

*   **Definition:** The PD term structure can be generated by integrating the hazard function over time or by iterating an adjusted transition matrix.
*   **Formula (hazard function):**
$$CumulativePD(t) = 1 - e^{-\int_0^t h(s) ds}$$
where:
    - $CumulativePD(t)$ is the cumulative probability of default up to time $t$.
    - $h(s)$ is the hazard function at time $s$

*   **Formula (transition matrix iteration):**

The $n$-year transition matrix is the $n$-th power of the one-year transition matrix.

$$TransitionMatrix_n = TransitionMatrix_1^n$$

Then, the probability of being in Default state by $n$ can be obtained from multiplying this transition matrix with the initial state vector (typically 'alive' for the entity).

## 3. Code Requirements

### 3.1 Libraries

*   `pandas`: For data manipulation and analysis.
*   `pandas_datareader`: For fetching macroeconomic data from FRED.
*   `numpy`: For numerical computations.
*   `scikit-learn` (`sklearn`): For building the PIT PD model (logistic regression, scaling).
*   `matplotlib`: For creating visualizations.
*   `seaborn`: For enhanced visualizations (e.g., heatmaps).
*   `lifelines` (optional): For Cox proportional hazards model.
*   `plotly` (optional): For interactive visualizations (e.g., Sankey diagrams).

### 3.2 Data Input/Output

*   **Input:**
    *   `ratings_case1.csv`: Raw ratings history (obligor_id, rating_date, internal_grade, default_flag, sector, exposure_eop).
    *   FRED macroeconomic data: GDPC1, UNRATE, CPIAUCSL, DCOILWTICO (quarter, gdp_growth_qoq, unemployment_rate, inflation_qoq, oil_price).
    *   `panel_default_rates.parquet`: Pre-calculated panel default rates (grade, window_end, num_exposed, num_defaults, default_rate).
*   **Output:**
    *   `ttc_pd_mapping_v1.csv`: TTC PD mapping table (grade, pd_mean, ci_lower, ci_upper).
    *   `pit_logreg_v1.pkl`: Trained PIT logistic regression model.
    *   `pit_coxph_v1.pkl` (optional): Trained PIT Cox proportional hazards model.
    *   `transition_matrix_v1.npy`: Transition matrix.
    *   `macro_scaler_v1.pkl`: Scaler for macroeconomic data.

### 3.3 Algorithms and Functions

1.  **`calculate_rolling_default_rates(ratings_data, window=12)`:**

    *   Input: `ratings_data` (DataFrame) with ratings history, `window` (int) representing the rolling window size in months.
    *   Output: DataFrame with rolling default rates by grade (grade, window_end, num_exposed, num_defaults, default_rate).
    *   Functionality: Calculates rolling default rates for each internal rating grade using a rolling 12-month window.
2.  **`derive_ttc_pd_mapping(default_rates_df)`:**

    *   Input: DataFrame with rolling default rates (output of `calculate_rolling_default_rates`).
    *   Output: DataFrame with TTC PD mapping (grade, pd_mean, ci_lower, ci_upper).
    *   Functionality: Calculates the mean default rate for each grade across the historical period. Implements Pluto-&-Tasche or Bayesian adjustments for low-default grades.
3.  **`train_pit_logistic_regression(panel_data, macro_data)`:**

    *   Input: `panel_data` (DataFrame) with historical default rates, `macro_data` (DataFrame) with macroeconomic data.
    *   Output: Trained logistic regression model and scaler.
    *   Functionality: Trains a logistic regression model to predict default based on rating grade and macroeconomic variables. Includes scaling of macroeconomic data.
4.  **`generate_pd_term_structure(pit_model, macro_scenario, transition_matrix)`:**

    *   Input: Trained PIT model, macroeconomic scenario (DataFrame), transtion matrix (NumPy Array).
    *   Output: DataFrame with multi-year PD term structure.
    *   Functionality: Generates multi-year PDs based on the PIT model and macroeconomic scenarios. Can use either hazard function integration or transition matrix iteration.

### 3.4 Visualizations

1.  **Time-series line plot of 1-yr default rates by grade:**  `matplotlib`
2.  **Heat-map of TTC PD table:** `seaborn.heatmap`
3.  **Calibration curve (predicted vs. observed) for PIT model on hold-out year:** `sklearn.calibration_curve`, `matplotlib`
4.  **Multi-year PD term structure fan chart (baseline vs. stress):** `matplotlib`
5.  **Sankey or chord diagram of 1-year transition matrix:** `plotly` (optional)

## 4. Additional Notes or Instructions

*   **Data Assumptions:** Assume that the `ratings_case1.csv` dataset contains complete and accurate ratings history for a representative portfolio.
*   **Macroeconomic Data:** Ensure that the macroeconomic data from FRED is aligned with the ratings data in terms of time period and frequency (quarterly).
*   **Model Validation:** Perform thorough model validation, including backtesting and out-of-sample testing, to ensure the model's predictive power and stability. The calibration curve is only a quick in-sample sanity check.
*   **Customization:** The notebook can be customized to incorporate different macroeconomic variables, model specifications, and stress scenarios.
*   **Reproducibility:** Ensure that all steps in the notebook are well-documented and reproducible. Use consistent random seeds for any stochastic processes. Save all intermediate data and model artefacts.
*   **Assumptions about cycle adjustment:** The "cycle adjustment" is vague and needs to be based on well-defined adjustments for each rating grade and well justified; ideally be based on the standard deviation or percentiles, rather than an arbitrary hardcoded number
